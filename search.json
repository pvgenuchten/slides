[
  {
    "objectID": "slides/intro-crawler-mcf-pycsw.html#what",
    "href": "slides/intro-crawler-mcf-pycsw.html#what",
    "title": "Metadata for the rest of us",
    "section": "What",
    "text": "What\n\nA set of conventions and tools to create and share metadata of datasets.\nData scientists should own metadata records, because they are the knowledgeable party.\nSo: integrate in their environment, stay close to the tools they already use: Python, Git, Excel.\nFocus on TC211 and academia standards, because we’re in the academic spatial domain"
  },
  {
    "objectID": "slides/intro-crawler-mcf-pycsw.html#some-principles",
    "href": "slides/intro-crawler-mcf-pycsw.html#some-principles",
    "title": "Metadata for the rest of us",
    "section": "Some principles",
    "text": "Some principles\n\nbased on existing standards/conventions\n(meta)data at the source\nsimple in maintenance\npersistent/traceable over time\nFixed (extendible) data model for metadata"
  },
  {
    "objectID": "slides/intro-crawler-mcf-pycsw.html#use-cases",
    "href": "slides/intro-crawler-mcf-pycsw.html#use-cases",
    "title": "Metadata for the rest of us",
    "section": "3 use cases",
    "text": "3 use cases\n\nA team of data scientists understands/describes their source data, models and data outputs, for tracability and future re-use\nAn organisation aims to share a subset of their resources as open access data\nA community aims to collect relevant remote resources in a thematic catalogue"
  },
  {
    "objectID": "slides/intro-crawler-mcf-pycsw.html#describe-resources-at-their-source",
    "href": "slides/intro-crawler-mcf-pycsw.html#describe-resources-at-their-source",
    "title": "Metadata for the rest of us",
    "section": "Describe resources at their source",
    "text": "Describe resources at their source\n\nBuilds on a convention of placing a README.md file in a project folder, describing the source, attribution.\nSuggestion is to use a structured format, so also machines can understand this information\nMetadata control file (mcf) is a convention of the geopython community (in YAML)\nA crawler tool extracts embedded metadata from data to create initial mcf\nA crawler tool fetches from a set of project folders the metadata and stores it in a central index, pycsw"
  },
  {
    "objectID": "slides/intro-crawler-mcf-pycsw.html#schematic-i",
    "href": "slides/intro-crawler-mcf-pycsw.html#schematic-i",
    "title": "Metadata for the rest of us",
    "section": "Schematic I",
    "text": "Schematic I\n\n\n\n\n\nflowchart TB\n    P[Project folder] --&gt;|Files| CI{{crawler}}\n    CI --&gt;|Extract metadata| P\n    CI --&gt; G[Git] \n    G --&gt; PYCSW"
  },
  {
    "objectID": "slides/intro-crawler-mcf-pycsw.html#share-as-open-access-data",
    "href": "slides/intro-crawler-mcf-pycsw.html#share-as-open-access-data",
    "title": "Metadata for the rest of us",
    "section": "Share as open access data",
    "text": "Share as open access data\n\nBuilds on the previous case, data scientists store and describe their data outputs on a central folder, a sharable subset is shared via pycsw.\nFor spatial assets OGC data api’s are created, sharing the data as WMS, WFS, WCS using mapserver\nThe mcf content is used to create the mapserver configuration, the metadata is updated with the relevant OWS endpoints"
  },
  {
    "objectID": "slides/intro-crawler-mcf-pycsw.html#schematic-ii",
    "href": "slides/intro-crawler-mcf-pycsw.html#schematic-ii",
    "title": "Metadata for the rest of us",
    "section": "Schematic II",
    "text": "Schematic II\n\n\n\n\n\nflowchart TB\n    G[Git] --&gt;|mcf| CI{{crawler}} \n    CI --&gt;|mapfiles| MS[Mapserver]\n    Metadata --&gt; OWS\n    MS --&gt; OWS[WMS/WFS]\n    CI --&gt;|OWS Linkage| G"
  },
  {
    "objectID": "slides/intro-crawler-mcf-pycsw.html#a-thematic-participatory-data-portal",
    "href": "slides/intro-crawler-mcf-pycsw.html#a-thematic-participatory-data-portal",
    "title": "Metadata for the rest of us",
    "section": "A thematic participatory data portal",
    "text": "A thematic participatory data portal\n\nmetadata from external sources can be harvested to the central index\nby storing MCF in GIT, and add a ‘edit me on git’ link on each metadata page, so users can flag problems in metadata or suggest new content\nalso the harvest definition is stored on git\nImports are managed as CI-CD actions in Git"
  },
  {
    "objectID": "slides/intro-crawler-mcf-pycsw.html#metadata-harvest",
    "href": "slides/intro-crawler-mcf-pycsw.html#metadata-harvest",
    "title": "Metadata for the rest of us",
    "section": "Metadata harvest",
    "text": "Metadata harvest\n\na generic query to a remote catalogue endpoint (csw, oai-pmh)\na excel sheet of records (each column is a metadata property)\na list of DOI’s"
  },
  {
    "objectID": "slides/intro-crawler-mcf-pycsw.html#schematic-iii",
    "href": "slides/intro-crawler-mcf-pycsw.html#schematic-iii",
    "title": "Metadata for the rest of us",
    "section": "Schematic III",
    "text": "Schematic III\n\n\n\n\n\nflowchart TB\n    G[Git] --&gt;|mcf| CI{{pygeometa}} \n    CI --&gt;|iso19139| DB[(Database)]\n    DB --&gt; C(Catalogue)\n    C --&gt; G\n    C --&gt; CSW(CSW)\n    C --&gt; OAR(OGCAPI Records)\n    C --&gt; OAI(OAI-PMH)"
  },
  {
    "objectID": "slides/intro-crawler-mcf-pycsw.html#oh-but-this-is-too-technical",
    "href": "slides/intro-crawler-mcf-pycsw.html#oh-but-this-is-too-technical",
    "title": "Metadata for the rest of us",
    "section": "Oh, but this is too technical!",
    "text": "Oh, but this is too technical!\n\nIs it?\nISO19139 and DCAT and their tools (GeoNetwork, CKAN, Dataverse) also have their peculiarities\nNot everybody will be able to create a pull request in GIT, use git issues instead and let others in the community fix\nYAML has its caveats (indenting, reserved characters), use YAML check in text editor\nWe created a web-form for mcf editing, mdme"
  },
  {
    "objectID": "slides/intro-crawler-mcf-pycsw.html#read-more",
    "href": "slides/intro-crawler-mcf-pycsw.html#read-more",
    "title": "Metadata for the rest of us",
    "section": "Read more?",
    "text": "Read more?\n\npygeometa in the EJPSoil soil data assimilation cookbook\nLSC Hubs data workshop\npygeometa\nGeoDataCrawler"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Select your deck:",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJul 3, 2024\n\n\nA fun way to do spatial cataloguing\n\n\nPaul van Genuchten, Tom Kralidis\n\n\n\n\nNov 4, 2023\n\n\nAbandonded Project Websites -&gt; no\n\n\nPaul van Genuchten\n\n\n\n\nOct 19, 2023\n\n\nDocument your model data at minimal effort\n\n\nPaul van Genuchten, Giulio Genova\n\n\n\n\nFeb 29, 2024\n\n\nMetadata for the rest of us\n\n\nPaul van Genuchten, Tom Kralidis, Giulio Genova\n\n\n\n\nMay 20, 2024\n\n\nParticipatory data catalogs to facilitate informed decision-making\n\n\nvan Genuchten, P; Genova, G; van der Woude, T; van Egmond, F; Fantappiè, M; Kempen, B; Kralidis, T;\n\n\n\n\nJul 3, 2024\n\n\nSDI maintenance DevOps style\n\n\nPaul van Genuchten\n\n\n\n\nJun 3, 2024\n\n\nSoilwise & Metadata\n\n\nPaul van Genuchten\n\n\n\n\nNov 13, 2023\n\n\nWorkshop pygeoapi\n\n\nPaul van Genuchten\n\n\n\n\n \n\n\ntype: default\n\n\n \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "slides/soilwise-metadata.html#what-is-metadata",
    "href": "slides/soilwise-metadata.html#what-is-metadata",
    "title": "Soilwise & Metadata",
    "section": "What is metadata",
    "text": "What is metadata\n\nData about data\nSupports findability (where, what, who)\nSupports interoperability (use standards and common vocabularies)\nSupports reusability (data license, data provenance)"
  },
  {
    "objectID": "slides/soilwise-metadata.html#findability",
    "href": "slides/soilwise-metadata.html#findability",
    "title": "Soilwise & Metadata",
    "section": "Findability",
    "text": "Findability\n\nWhen was this file created, by who, why?\nDidn’t project XX create a report about YY?\nHow many articles have been published on ZZ in period TT?\nHow many times has this article been cited?\nWhich datasets were used to generate this prediction?\nHow can this dataset be uniquely referenced?"
  },
  {
    "objectID": "slides/soilwise-metadata.html#where-can-you-store-metadata",
    "href": "slides/soilwise-metadata.html#where-can-you-store-metadata",
    "title": "Soilwise & Metadata",
    "section": "Where can you store metadata?",
    "text": "Where can you store metadata?\n\nAlongside a data file/table/report (sidecar) or embedded (.doc, .xsl, .pdf)\nProduced during registration and stored in a repository\nIn a catalogue"
  },
  {
    "objectID": "slides/soilwise-metadata.html#how-is-metadata-generatedenriched",
    "href": "slides/soilwise-metadata.html#how-is-metadata-generatedenriched",
    "title": "Soilwise & Metadata",
    "section": "How is metadata generated/enriched?",
    "text": "How is metadata generated/enriched?\n\nSystems generate metadata while data is produced\nAuthors provide metadata\nSystems enrich metadata with for example performance indicators, translations or linkages"
  },
  {
    "objectID": "slides/soilwise-metadata.html#how-do-you-standardise-metadata",
    "href": "slides/soilwise-metadata.html#how-do-you-standardise-metadata",
    "title": "Soilwise & Metadata",
    "section": "How do you standardise metadata?",
    "text": "How do you standardise metadata?\n\nCreate metadata using common metadata tools\nPrefer keywords from common thesauri\nAgree on and comply with a metadata profile for your community"
  },
  {
    "objectID": "slides/soilwise-metadata.html#how-do-you-share-metadata",
    "href": "slides/soilwise-metadata.html#how-do-you-share-metadata",
    "title": "Soilwise & Metadata",
    "section": "How do you share metadata?",
    "text": "How do you share metadata?\n\nYou register your artifact in a repository, including metadata\nYour organisation shares your project repository online\nYou post your metadata to a catalogue"
  },
  {
    "objectID": "slides/soilwise-metadata.html#how-become-cordis-and-euso-aware-of-my-metadata",
    "href": "slides/soilwise-metadata.html#how-become-cordis-and-euso-aware-of-my-metadata",
    "title": "Soilwise & Metadata",
    "section": "How become Cordis and EUSO aware of my metadata?",
    "text": "How become Cordis and EUSO aware of my metadata?\n\nYou register your project outputs in REA portal\nYou register project outputs in dedicated catalogues\nCatalogues harvest at intervals from relevant repositories"
  },
  {
    "objectID": "slides/soilwise-metadata.html#euso-metadata-profile",
    "href": "slides/soilwise-metadata.html#euso-metadata-profile",
    "title": "Soilwise & Metadata",
    "section": "EUSO metadata profile",
    "text": "EUSO metadata profile\n\n75% generic metadata properties (title, keywords, date, author)\n15% specific soil related keywords (properties, threads, functions)\n10% EUSO related keywords (EUSO working group, Horizon Europe funding)"
  },
  {
    "objectID": "slides/soilwise-metadata.html#how-to-adopt-the-profile",
    "href": "slides/soilwise-metadata.html#how-to-adopt-the-profile",
    "title": "Soilwise & Metadata",
    "section": "How to adopt the profile?",
    "text": "How to adopt the profile?\n\nMany repositories (including Zenodo, Dataverse) have an option to provide subjects, which is a combination of thesaurus + keyword.\nEUSO endorses to select 1 or multiple keywords from 10-ish thesauri."
  },
  {
    "objectID": "slides/soilwise-metadata.html#what-is-the-benefit-of-adopting-the-profile",
    "href": "slides/soilwise-metadata.html#what-is-the-benefit-of-adopting-the-profile",
    "title": "Soilwise & Metadata",
    "section": "What is the benefit of adopting the profile?",
    "text": "What is the benefit of adopting the profile?\n\nNo risk of forgetting important elements\nYour metadata (included by a filter) will be harvested\nProject output are found, when users apply filters\nProject outputs will be included in aggregated statistics"
  },
  {
    "objectID": "slides/alliander-2023.html#about",
    "href": "slides/alliander-2023.html#about",
    "title": "Workshop pygeoapi",
    "section": "About",
    "text": "About\n\n90’s Bodemkunde Wageningen\n00’s Nieuwland GeoInformatie\n\nWebGIS at Alliander (OpenLayers, tilecache, Smallworld)\n\n10’s GeoCat BV, GeoNetwork/GeoServer\n\nProvincie Zeeland\n\n20’s ISRIC - World Soil Information"
  },
  {
    "objectID": "slides/alliander-2023.html#soil-museum",
    "href": "slides/alliander-2023.html#soil-museum",
    "title": "Workshop pygeoapi",
    "section": "Soil Museum",
    "text": "Soil Museum"
  },
  {
    "objectID": "slides/alliander-2023.html#soilgrids",
    "href": "slides/alliander-2023.html#soilgrids",
    "title": "Workshop pygeoapi",
    "section": "Soilgrids",
    "text": "Soilgrids"
  },
  {
    "objectID": "slides/alliander-2023.html#section",
    "href": "slides/alliander-2023.html#section",
    "title": "Workshop pygeoapi",
    "section": "",
    "text": "EU research project met als doel om data rond bodem beter te gebruiken / behouden (FAIR)\nStart met onderzoeken van user stories vanuit 5 werkvelden (landbouw, onderzoek, overheid, breder publiek, business)\n\nsoilwise-he.eu"
  },
  {
    "objectID": "slides/alliander-2023.html#pygeoapi",
    "href": "slides/alliander-2023.html#pygeoapi",
    "title": "Workshop pygeoapi",
    "section": "pygeoapi",
    "text": "pygeoapi\n\nPresentation\ndive.pygeoapi.io"
  },
  {
    "objectID": "slides/abandoned-web.html#a-broken-link-from-a-report",
    "href": "slides/abandoned-web.html#a-broken-link-from-a-report",
    "title": "Abandonded Project Websites -> no",
    "section": "A broken link from a report?",
    "text": "A broken link from a report?\n\nor worse, arrive in an online casino from a link in a report?\nmany websites are abandoned few years after project finish\nwebsite builders should show ownership of domains they create\nreport writers should not link to dodgy locations (aka project websites)"
  },
  {
    "objectID": "slides/abandoned-web.html#an-initiative-to-recover-lost-content",
    "href": "slides/abandoned-web.html#an-initiative-to-recover-lost-content",
    "title": "Abandonded Project Websites -> no",
    "section": "An initiative to recover lost content",
    "text": "An initiative to recover lost content\n\nIdentify which websites with usefull information are lost\nRecover the content from archive.org or organisation backups\nReclaim the domains (restore linkage)\nJoin the efforts at github.com/soil-on-web/abandoned-webs"
  },
  {
    "objectID": "slides/abandoned-web.html#good-practices-on-url-persistence-of-project-websites",
    "href": "slides/abandoned-web.html#good-practices-on-url-persistence-of-project-websites",
    "title": "Abandonded Project Websites -> no",
    "section": "Good practices on url persistence of project websites",
    "text": "Good practices on url persistence of project websites\n\nuse a subdomain of an established organisation\nuse a persistent identifier framework, when linking to external sources\nset up rewrite rules at website cancelation\nuse minimal technology, yes: html; no: wordpress, liferay, …\nkeep the content minimal, link to external (persistent) resources\npre-pay the domain ownership for at least the upcoming 10 years"
  },
  {
    "objectID": "slides/fun-way-of-spatial-cataloguing.html#participatory-metadata-management",
    "href": "slides/fun-way-of-spatial-cataloguing.html#participatory-metadata-management",
    "title": "A fun way to do spatial cataloguing",
    "section": "Participatory metadata management",
    "text": "Participatory metadata management\n\nUsers initially provided metadata as lists in Microsoft Excel\nMetadata is hosted in GitHub\nUsers contribute content (or register issues about content)"
  },
  {
    "objectID": "slides/fun-way-of-spatial-cataloguing.html#metadata-for-mapserver-configuration",
    "href": "slides/fun-way-of-spatial-cataloguing.html#metadata-for-mapserver-configuration",
    "title": "A fun way to do spatial cataloguing",
    "section": "Metadata for MapServer configuration",
    "text": "Metadata for MapServer configuration\n\nUse the metadata to generate MapServer mapfile configuration\nAdd the generated map endpoint to the metadata\nMapServer is fully aligned with the catalogue"
  },
  {
    "objectID": "slides/fun-way-of-spatial-cataloguing.html#terriajs-a-web-based-gis",
    "href": "slides/fun-way-of-spatial-cataloguing.html#terriajs-a-web-based-gis",
    "title": "A fun way to do spatial cataloguing",
    "section": "TerriaJS, a web-based GIS",
    "text": "TerriaJS, a web-based GIS\n\nThe project uses TerriaJS as a data viewer\nTerriaJS includes a CSW Catalogue search and links back to the catalogue via WMS capabilities\nExtra integration via ‘Add data to viewer’ from catalogue page"
  },
  {
    "objectID": "slides/fun-way-of-spatial-cataloguing.html#terriajs",
    "href": "slides/fun-way-of-spatial-cataloguing.html#terriajs",
    "title": "A fun way to do spatial cataloguing",
    "section": "TerriaJS",
    "text": "TerriaJS\n\nTerriaJS"
  },
  {
    "objectID": "slides/fun-way-of-spatial-cataloguing.html#workflow",
    "href": "slides/fun-way-of-spatial-cataloguing.html#workflow",
    "title": "A fun way to do spatial cataloguing",
    "section": "Workflow",
    "text": "Workflow\n“No code”: Manage, verify and publish metadata using GitHub as a content management platform.\n\nMetadata files are managed as pygeometa MCF records\nGitHub Actions are used to verify, transform and publish notification messages to an MQTT broker\nFrom here, a metadata registrar is subscribed to the same MQTT broker and, on notification, verifies new/updated metadata and publishes to an OGC API - Records endpoint (powered by pygeoapi) using OGC API - Features - Part 4. The QGIS desktop application is then used to query the OGC API - Records endpoint using its MetaSearch search client."
  },
  {
    "objectID": "slides/fun-way-of-spatial-cataloguing.html#workflow-1",
    "href": "slides/fun-way-of-spatial-cataloguing.html#workflow-1",
    "title": "A fun way to do spatial cataloguing",
    "section": "Workflow",
    "text": "Workflow"
  },
  {
    "objectID": "slides/fun-way-of-spatial-cataloguing.html#references",
    "href": "slides/fun-way-of-spatial-cataloguing.html#references",
    "title": "A fun way to do spatial cataloguing",
    "section": "References",
    "text": "References\n\npygeometa\npycsw.org v3.0b\npyGeoDataCrawler v1.3\nOGCAPI - Records v1.0\nmapserver.org v8.2\nterria.io\n\n\n\n\n\nFOSS4G Europe 2024, Tartu, Estonia"
  },
  {
    "objectID": "slides/pitch-battle.html#improving-findability---devops-style",
    "href": "slides/pitch-battle.html#improving-findability---devops-style",
    "title": "Document your model data at minimal effort",
    "section": "Improving findability - devops style",
    "text": "Improving findability - devops style\n\nWhat: Document your modelling data with minimal effort\nWhy: Better findability and (re)usability of data\nWhat’s next: Adopt the efforts in ongoing projects & extend the user community"
  },
  {
    "objectID": "slides/pitch-battle.html#setting-concept",
    "href": "slides/pitch-battle.html#setting-concept",
    "title": "Document your model data at minimal effort",
    "section": "Setting & Concept",
    "text": "Setting & Concept\n\nSetting: Data management in predictive modelling\n\nIn soil modelling we handle many data sources\nThese files are stored on a network drive\nMetadata management is complex/dull/****\n\nThe sidecar concept\n\nAdd minimal metadata on a sidecar file\nA crawler extracts metadata from a file repository\nCrawled records are placed in a searchable index"
  },
  {
    "objectID": "slides/pitch-battle.html#pygeometa-geodatacrawler-pycsw",
    "href": "slides/pitch-battle.html#pygeometa-geodatacrawler-pycsw",
    "title": "Document your model data at minimal effort",
    "section": "pygeometa, geodatacrawler & pycsw",
    "text": "pygeometa, geodatacrawler & pycsw\n\npygeometa’s MCF is a minimal subset of ISO19115, encoded in yaml\ngeodatacrawler extends pygeometa to:\n\nextract metadata from data formats\ninherit metadata from parent folders\nimport metadata from csv and remote sources\ncreate data api’s based on metadata\n\n is a pythonic catalogue web app. Wide standards support enables findability in multiple communities."
  },
  {
    "objectID": "slides/tartu-devops-sdi.html#some-screenshots",
    "href": "slides/tartu-devops-sdi.html#some-screenshots",
    "title": "SDI maintenance DevOps style",
    "section": "Some screenshots",
    "text": "Some screenshots"
  },
  {
    "objectID": "slides/index.html",
    "href": "slides/index.html",
    "title": "some slide decks",
    "section": "",
    "text": "A fun way to do spatial cataloguing\n\n\nData discovery using pygeometa and mdme\n\n\n\n\n\n\n\n\nJul 3, 2024\n\n\nPaul van Genuchten, Tom Kralidis\n\n\n\n\n\n\n\n\n\n\n\n\nAbandonded Project Websites -&gt; no\n\n\nan initiative to increase awareness on (not) abandoning websites at project finish\n\n\n\n\n\n\n\n\nNov 4, 2023\n\n\nPaul van Genuchten\n\n\n\n\n\n\n\n\n\n\n\n\nDocument your model data at minimal effort\n\n\nA pitch battle at digital innovation expo @WUR\n\n\n\n\n\n\n\n\nOct 19, 2023\n\n\nPaul van Genuchten, Giulio Genova\n\n\n\n\n\n\n\n\n\n\n\n\nMetadata for the rest of us\n\n\nIntro to a set of metadata conventions and tools\n\n\n\n\n\n\n\n\nFeb 29, 2024\n\n\nPaul van Genuchten, Tom Kralidis, Giulio Genova\n\n\n\n\n\n\n\n\n\n\n\n\nParticipatory data catalogs to facilitate informed decision-making\n\n\n\n\n\n\n\n\n\n\n\nMay 20, 2024\n\n\nvan Genuchten, P; Genova, G; van der Woude, T; van Egmond, F; Fantappiè, M; Kempen, B; Kralidis, T;\n\n\n\n\n\n\n\n\n\n\n\n\nSDI maintenance DevOps style\n\n\nInspired and facilitated by Open Source\n\n\nAt ISRIC - World Soil Information we increasingly maintain our data services through CI-CD pipelines configured via GIT. Both from the service as well as content perspective. The starting point are metadata records of our datasets being stored on GIT. With every change of a record, the relevant catalogues (pycsw) get updated and any relevant web services (mapserver) are updated. These pipelines are reproducable and there are never inconsistencies between catalogue content and the services. On top of that our users can directly report issues (or even improvement suggestions) through git. The stack is build on proven OSGeo components. A tool pyGeoDataCrawler brings the power of GDAL and pygeometa to CI-CD scripting. It crawls files on a folder and extracts relevant metadata, then prepares a mapserver configuration for that folder, while updating the metadata with the relevant service url’s. Typical use cases for this stack are; a search interface to any file based data repository or a participatory data catalogue for a project. At the conference we hope to hear from you if any of these components could be relevant to your cases or if there are similar initiatives we can contribute to or benefit from. What’s next? At ISRIC we receive and ingest a lot of soil data from partners. To harmonize this data is a huge effort. Via automated pipelines and interaction with the submitters via git comments, we hope to improve also this aspect of the data management cycle.\n\n\n\n\n\nJul 3, 2024\n\n\nPaul van Genuchten\n\n\n\n\n\n\n\n\n\n\n\n\nSoilwise & Metadata\n\n\nMetadata in Horizon Europe projects (Soil Mission)\n\n\n\n\n\n\n\n\nJun 3, 2024\n\n\nPaul van Genuchten\n\n\n\n\n\n\n\n\n\n\n\n\nWorkshop pygeoapi\n\n\nAlliander OS Event\n\n\n\n\n\n\n\n\nNov 13, 2023\n\n\nPaul van Genuchten\n\n\n\n\n\n\nNo matching items"
  }
]